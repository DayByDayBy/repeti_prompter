{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d5dc014-1b88-4a08-a06f-ff2117dcdb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "from typing import Dict, List, Any, Optional\n",
    "import json\n",
    "from datetime import datetime\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(filename='tree_generation.log', level=logging.ERROR,\n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "TIME_STAMP = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "MODEL_NAME = 'dolphin-mistral'\n",
    "CHAIN_LENGTH = 3\n",
    "RECURSION_DEPTH = 3\n",
    "SHAPE = f'{CHAIN_LENGTH} by {RECURSION_DEPTH}'\n",
    "PROMPT_NICKNAME = 'recursion_prompt'\n",
    "INITIAL_PROMPT = \"\"\"i think that the ability to recursively improve upon the present \n",
    "is the key to unlocking the boundless potential of the future, a tool of the gods, \n",
    "the engine of progress, the ultimate weapon in the battle against entropy.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd25fbab-533d-4ee3-9f0c-4d1993106447",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(prompt: str) -> str:\n",
    "    try:\n",
    "        return ollama.generate(model=MODEL_NAME, prompt=prompt)['response']\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error generating response: {e}\")\n",
    "        return \"\"\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eaa89cc0-0275-497b-80df-c6342f96db35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_chain(seed_prompt: str, chain_length: int) -> List[str]:\n",
    "    chain = [seed_prompt]\n",
    "    for _ in tqdm(range(chain_length), desc=\"generating chain\", leave=False):\n",
    "        response = generate_response(chain[-1])\n",
    "        if response:\n",
    "            chain.append(response)\n",
    "        else:\n",
    "            break\n",
    "    return chain\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9626291f-78be-427a-9e83-5f83313cff14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tree(seed_prompt: str, chain_length: int, recursion_depth: int) -> Dict[str, Any]:\n",
    "    chain = generate_chain(seed_prompt, chain_length)\n",
    "    tree = {\"prompt\": seed_prompt, \"responses\": chain[1:]}\n",
    "    \n",
    "    if recursion_depth > 1:\n",
    "        tree[\"children\"] = []\n",
    "        for response in tqdm(chain[1:], desc=f\"recursion depth {recursion_depth}\", leave=False):\n",
    "            child_tree = generate_tree(response, chain_length, recursion_depth - 1)\n",
    "            tree[\"children\"].append(child_tree)\n",
    "    \n",
    "    return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51ae2bc9-07d5-46ff-88e0-17daa57ad910",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_tree(tree: Dict[str, Any], metadata: Dict[str, Any], filename: Optional[str] = None):\n",
    "    full_tree = {\n",
    "        \"metadata\": metadata,\n",
    "        \"content\": tree\n",
    "    }\n",
    "    \n",
    "    if filename is None:\n",
    "        filename = f'./responses/tree_{metadata[\"model_name\"]}_at_{metadata[\"timestamp\"]}.json'\n",
    "    os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(full_tree, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7b7850b-0516-4a36-bea6-8d555cff43d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Running dolphin-mistral model\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "recursion depth 2:   0%|                                                        | 0/2 [00:00<?, ?it/s]\n",
      "generating chain:   0%|                                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "generating chain:  50%|████████████████████████▌                        | 1/2 [00:05<00:05,  5.77s/it]\u001b[A\n",
      "generating chain: 100%|█████████████████████████████████████████████████| 2/2 [00:14<00:00,  7.51s/it]\u001b[A\n",
      "recursion depth 2:  50%|████████████████████████                        | 1/2 [00:14<00:14, 14.51s/it]\u001b[A\n",
      "generating chain:   0%|                                                         | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "generating chain:  50%|████████████████████████▌                        | 1/2 [00:05<00:05,  5.01s/it]\u001b[A\n",
      "generating chain: 100%|█████████████████████████████████████████████████| 2/2 [00:09<00:00,  4.65s/it]\u001b[A\n",
      "                                                                                                      \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "generated tree saved.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    print(f'\\n\\nRunning {MODEL_NAME} model\\n\\n')\n",
    "    \n",
    "    metadata = {\n",
    "        \"tree_key\": f'{PROMPT_NICKNAME}_{MODEL_NAME}',\n",
    "        \"timestamp\": TIME_STAMP,\n",
    "        \"shape\": SHAPE,\n",
    "        \"model_name\": MODEL_NAME,\n",
    "        \"chain_length\": CHAIN_LENGTH,\n",
    "        \"recursion_depth\": RECURSION_DEPTH\n",
    "    }\n",
    "    \n",
    "    tree = generate_tree(INITIAL_PROMPT, CHAIN_LENGTH, RECURSION_DEPTH)\n",
    "    save_tree(tree, metadata)\n",
    "    \n",
    "    print(\"\\n\\ngenerated tree saved.\\n\\n\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3 repeti (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
